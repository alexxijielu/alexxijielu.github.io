<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Lu</title>
    <link>http://www.alexluresearch.com/</link>
      <atom:link href="http://www.alexluresearch.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Alex Lu</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 30 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Alex Lu</title>
      <link>http://www.alexluresearch.com/</link>
    </image>
    
    <item>
      <title>Discovering molecular features of intrinsically disordered regions by using evolution for contrastive learning</title>
      <link>http://www.alexluresearch.com/publication/reverse-homology/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/reverse-homology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improved Conditional Flow Models for Molecule to Image Synthesis</title>
      <link>http://www.alexluresearch.com/publication/conditional_flow/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/conditional_flow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evolution Is All You Need: Phylogenetic Augmentation for Contrastive Learning</title>
      <link>http://www.alexluresearch.com/publication/evolution_is_all_you_need/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/evolution_is_all_you_need/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Out-of-Sample Generalization</title>
      <link>http://www.alexluresearch.com/project/out-of-sample/</link>
      <pubDate>Tue, 03 Mar 2020 17:18:58 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/out-of-sample/</guid>
      <description>&lt;img src=&#34;coos_preprint.png&#34;&gt;
&lt;p&gt;To automate the analysis of images, machine learning experts will often build classifiers, statistical models that assign useful labels to input images (such as if a cell is healthy or diseased.) For these classifiers to be useful, they must generalize, or be able to accurately label new data that has never been used to develop the model. However, a growing concern in machine learning is that we may be overestimating how generalizable classifiers are with standard techniques. Typically, an expert will evaluate their method by holding out some data, and then evaluating performance on that data to simulate the condition where the classifier is given fresh, unseen data. However, these types of methods don&amp;rsquo;t capture the cases where there may be changes in the way the data is produced and generated - for example, different hospitals have different instruments, so classifiers shown to work on one hospital&amp;rsquo;s data will not always work as well for another&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;To help machine learning experts develop methods that are robust to new data from different sources, we released a dataset where evaluation data increasingly differs from the data the experts are provided with to develop their models. For example, our hardest dataset comprises of data collected from a different laboratory in Ottawa, under a different microscope. We found that all of the current methods used to classify cells are not robust when the new data is different enough from the original data; we hope that by providing this dataset, machine learning experts will eventually be able to build methods that are robust to these effects.&lt;/p&gt;
&lt;p&gt;One observation we made about covariate shifts is that they often tend to be local: different classes are differently affected by covariate shifts, and in different ways from dataset to dataset. This suggests that correcting for covariate shifts locally may be a promising direction: we previously showed that a simple algorithm that uses the nearest neighbors of a protein can correct for covariate shifts, because usually, the nearest neighbors are informative about the kind of local covariate shift affecting that protein.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Representation Learning</title>
      <link>http://www.alexluresearch.com/project/representation-learning/</link>
      <pubDate>Tue, 03 Mar 2020 17:18:52 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/representation-learning/</guid>
      <description>&lt;img src=&#34;model.png&#34;&gt;
&lt;p&gt;Machine learning promises automation. In an era where we can generate millions of images in a day, we&amp;rsquo;d really like a computer to be able to look at these images for us and identify which ones are most interesting. But in practice, to implement machine learning, users either have to label potentially millions of images to train a neural network, so it&amp;rsquo;s not much less effort than just looking at screens manually.&lt;/p&gt;
&lt;p&gt;To address this issue, we use self-supervised learning. Self-supervised learning methods train deep learning models to solve autonomous proxy tasks. The proxy tasks do not need to produce useful outputs, and are only meant to teach the models transferable skills and perceptions of data: self-supervised proxy tasks often resemble puzzles, like solving jigsaw puzzles or determining how an image has been rotated.&lt;/p&gt;
&lt;p&gt;By designing specialized self-supervised learning tasks that rely on an understanding of nuanced biology to solve, our models automatically teach themselves protein biology - no manual labeling required. We learned &amp;ldquo;representations&amp;rdquo; of images using a task called &amp;ldquo;paired cell inpainting&amp;rdquo;. These representations perform better than those laboriously designed by experts in analyses like classifying protein subcellular localization, suggesting that they capture more biology. In addition, our methods are general: we were able to analyze datasets that were never analyzed computationally previously due to technical challenges.&lt;/p&gt;
&lt;p&gt;We also applied these methods to the intrinsically disordered &amp;ldquo;dark proteome&amp;rdquo;. These are regions of proteins that don&amp;rsquo;t fold into a stable secondary/tertiary structure. Although they are widespread and critical to protein function, we still don&amp;rsquo;t understand them well because they evolve too rapidly to be analyzed by classic bioinformatics methods. By creating a self-supervised method, &amp;ldquo;reverse homology&amp;rdquo;, that exploits principles of evolutions to learn about conserved elements of these sequences, we can automatically learn hundreds of important features that must be conserved over evolution for these regions of proteins to carry out their function. Interpreting these features lets us produce hypotheses that fuel biological discovery.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploratory Biology</title>
      <link>http://www.alexluresearch.com/project/exploratory-biology/</link>
      <pubDate>Tue, 03 Mar 2020 17:17:22 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/exploratory-biology/</guid>
      <description>&lt;p&gt;In applying machine learning to biology, a lot of work has been done in figuring out to automate routine processes that don&amp;rsquo;t scale well, such as building classifiers to assign labels to images. While still useful, these methods can typically only find more examples of biology that we already know a lot about. However, biologists are also interested in discovery: what phenotypes did we miss because they are too rare, or only occur in certain conditions? How do phenotypes correlate with disease or molecular functions? Is a biological phenotype really a group of multiple subclasses informed by different underlying mechanisms?&lt;/p&gt;
&lt;p&gt;Relatively little work has been dedicated to leveraging machine learning for exploratory biology. I research ways to create unbiased representations of biology through self-supervised learning: because these models &amp;ldquo;teach themselves&amp;rdquo; instead of relying on prior knowledge from experts, they may learn to look at different aspects of cells or proteins that experts are biased by. By looking at patterns or commonalities in these representations, we can discover interesting new hypotheses.&lt;/p&gt;
&lt;p&gt;In a proof-of-concept, we analyzed the entire yeast proteome in 24 different screens - integrating over 600,000 different images in this study. We found a lot of cool patterns in the ways different proteins responded, that were unexpected - for example, in addition to finding specific and general responses to stress, we also found proteins that would behave in really different ways in different stresses, or unexpected changes in proteins that were thought to do one thing, but had a change that implied that they were functional in different ways. These analysis help us come up with new biological hypotheses, highlighting biology that biologists wouldn&amp;rsquo;t have previously noticed without these types of big, systematic analyses.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Cells Out of Sample (COOS) dataset and benchmarks for measuring out-of-sample generalization of image classifiers</title>
      <link>http://www.alexluresearch.com/publication/coos/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/coos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>YeastSpotter: accurate and parameter-free web segmentation for microscopy images of yeast cells</title>
      <link>http://www.alexluresearch.com/publication/yeastspotter/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/yeastspotter/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</title>
      <link>http://www.alexluresearch.com/publication/paired-cell-inpainting/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/paired-cell-inpainting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integrating images from multiple microscopy screens reveals diverse patterns of change in the subcellular localization of proteins</title>
      <link>http://www.alexluresearch.com/publication/integrating-yeast-images/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/integrating-yeast-images/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Influence of repetitive mechanical loading on MMP2 activity in tendon fibroblasts</title>
      <link>http://www.alexluresearch.com/publication/mmp2/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/mmp2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Unsupervised kNN Method to Systematically Detect Changes in Protein Localization in High-Throughput Microscopy Images</title>
      <link>http://www.alexluresearch.com/publication/knn/</link>
      <pubDate>Thu, 21 Jul 2016 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/knn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mast cells exert pro-inflammatory effects of relevance to the pathophyisology of tendinopathy</title>
      <link>http://www.alexluresearch.com/publication/angiopoietin/</link>
      <pubDate>Wed, 16 Dec 2015 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/angiopoietin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accumulation of oxidized LDL in the tendon tissues of C57BL/6 or apolipoprotein E knock-out mice that consume a high fat diet: potential impact on tendon health</title>
      <link>http://www.alexluresearch.com/publication/oxidized-ldl/</link>
      <pubDate>Fri, 12 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/oxidized-ldl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhanced collagen type I synthesis by human tenocytes subjected to periodic in vitro mechanical stimulation</title>
      <link>http://www.alexluresearch.com/publication/enhanced_collagen/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/enhanced_collagen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mast cells exert pro-inflammatory effects of relevance to the pathophyisology of tendinopathy</title>
      <link>http://www.alexluresearch.com/publication/podocalyxin/</link>
      <pubDate>Fri, 10 Oct 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/podocalyxin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mast cells exert pro-inflammatory effects of relevance to the pathophyisology of tendinopathy</title>
      <link>http://www.alexluresearch.com/publication/mast_cells/</link>
      <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/mast_cells/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
