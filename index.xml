<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex Lu</title>
    <link>http://www.alexluresearch.com/</link>
      <atom:link href="http://www.alexluresearch.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Alex Lu</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 08 Nov 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Alex Lu</title>
      <link>http://www.alexluresearch.com/</link>
    </image>
    
    <item>
      <title>ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles</title>
      <link>http://www.alexluresearch.com/publication/asl_stem_wiki/</link>
      <pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/asl_stem_wiki/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ASL citizen: a community-sourced dataset for advancing isolated sign language recognition</title>
      <link>http://www.alexluresearch.com/publication/asl_citizen/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/asl_citizen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Systemic Biases in Sign Language AI Research: A Deaf-Led Call to Reevaluate Research Agendas</title>
      <link>http://www.alexluresearch.com/publication/asl_systematic_biases/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/asl_systematic_biases/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convolutions are competitive with transformers for protein sequence pretraining</title>
      <link>http://www.alexluresearch.com/publication/carp/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/carp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Protein structure generation via folding diffusion</title>
      <link>http://www.alexluresearch.com/publication/foldingdiff/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/foldingdiff/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature reuse and scaling: Understanding transfer learning with protein language models</title>
      <link>http://www.alexluresearch.com/publication/feature_reuse_proteins/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/feature_reuse_proteins/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Domain adaptation using optimal transport for invariant learning using histopathology datasets</title>
      <link>http://www.alexluresearch.com/publication/domain_adaptation_histopathology_ot/</link>
      <pubDate>Tue, 23 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/domain_adaptation_histopathology_ot/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessing the limits of zero-shot foundation models in single-cell biology</title>
      <link>http://www.alexluresearch.com/publication/sc_foundation_zero_shot/</link>
      <pubDate>Fri, 27 Oct 2023 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/sc_foundation_zero_shot/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Protein generation with evolutionary diffusion: sequence is all you need</title>
      <link>http://www.alexluresearch.com/publication/evodiff/</link>
      <pubDate>Tue, 12 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/evodiff/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A functional map of the human intrinsically disordered proteome</title>
      <link>http://www.alexluresearch.com/publication/human_idr_proteome/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/human_idr_proteome/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Incorporating knowledge of plates in batch normalization improves generalization of deep learning for microscopy images</title>
      <link>http://www.alexluresearch.com/publication/ben/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/ben/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self-Supervised Learning</title>
      <link>http://www.alexluresearch.com/project/self-supervised/</link>
      <pubDate>Mon, 08 Aug 2022 17:18:52 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/self-supervised/</guid>
      <description>&lt;img src=&#34;model.png&#34;&gt;
&lt;p&gt;Machine learning promises automation. In an era where we can generate millions of images in a day, we&amp;rsquo;d really like a computer to be able to look at these images for us and identify which ones are most interesting. But in practice, to implement machine learning, users either have to label potentially millions of images to train a neural network, so it&amp;rsquo;s not much less effort than just looking at screens manually.&lt;/p&gt;
&lt;p&gt;To address this issue, we use self-supervised learning. Self-supervised learning methods are inspired by developmental psychology. Unlike state-of-the-art machine learning methods, which rely on more rote learning strategies, children learn skills through play and exploration. Similarly, training neural networks on autonomous puzzle-solving tasks can help them develop skills and representations that can be transferred to more useful analyses. By carefully designing the task to recognize specific biology in images, we can control what the model learns.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007348&#34;&gt;For microscopy images, we designed a task called &amp;ldquo;paired cell inpainting&amp;quot;&lt;/a&gt;. We ask the model to solve a &amp;ldquo;coloring book&amp;rdquo; challenge: the task asks it to recognize protein localization in one cell, so it can color in the right organelle in a second different cell. Since this task implicitly requires an understanding of protein localization in the first cell, this representation can be transferred to downstream analyses. Our representations perform better than those laboriously designed by experts in classifying protein subcellular localization, suggesting that they capture more biology. In addition, our method is general: we were able to analyze datasets that were never analyzed computationally previously due to technical challenges.&lt;/p&gt;
&lt;p&gt;We also applied these methods to the intrinsically disordered &amp;ldquo;dark proteome&amp;rdquo;. These are regions of proteins that don&amp;rsquo;t fold into a stable secondary/tertiary structure. Although they are widespread and critical to protein function, we still don&amp;rsquo;t understand them well because they evolve too rapidly to be analyzed by classic bioinformatics methods. &lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010238&#34;&gt;By creating a self-supervised method, &amp;ldquo;reverse homology&amp;quot;&lt;/a&gt;, that exploits principles of evolutions to learn about conserved elements of these sequences, we can automatically learn hundreds of important features that must be conserved over evolution for these regions of proteins to carry out their function. Interpreting these features lets us produce hypotheses that fuel biological discovery.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Biological Hypothesis Discovery</title>
      <link>http://www.alexluresearch.com/project/exploratory-biology/</link>
      <pubDate>Mon, 08 Aug 2022 17:17:22 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/exploratory-biology/</guid>
      <description>&lt;p&gt;How do we discover new biology using neural networks? Even as we&amp;rsquo;ve trained models that can sensitively detect biological signal, we still need a way to extract and organize these signals into actionable hypotheses. For example, what phenotypes did we miss because they are too rare, or only occur in certain conditions? How do phenotypes correlate with disease or molecular functions? Is a biological phenotype really a group of multiple subclasses informed by different underlying mechanisms? To address these challenges, I focus on two main strategies in my research: visualization and interpretation.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Visualization:&lt;/b&gt; Unsupervised cluster analyses can help group together representations learned by neural networks, so we can analyze patterns and global trends. We &lt;a href = &#39;https://elifesciences.org/articles/31872&#39;&gt;analyzed the entire yeast proteome in 24 different screens &lt;/a&gt; - integrating over 600,000 different images. We found a lot of cool patterns in the ways different proteins responded, that were unexpected - for example, in addition to finding specific and general responses to stress, we also found proteins that would behave in really different ways in different stresses, or unexpected changes in proteins that were thought to do one thing, but had a change that implied that they were functional in different ways. These analysis help us come up with new biological hypotheses, highlighting biology that biologists wouldn&amp;rsquo;t have previously noticed without these types of big, systematic analyses.&lt;/p&gt;
&lt;img src=&#34;protein.png&#34;&gt;
&lt;p&gt;&lt;b&gt;Interpretation methods:&lt;/b&gt; In our work &lt;a href=&#39;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010238&#39;&gt;understanding the intrinsically disordered &amp;ldquo;dark proteome&amp;quot;&lt;/a&gt;, we developed a method allowing us to interpret individual neurons of a neural network as sequence logos (showing the subsequences these neurons preferentially identified in protein sequences), as well as a method that allowed us to interpret what specific properties of any given sequence a neural network was relying on to identify evolutionary conservation in that sequence. We showed that we could identify things like new subclasses of motifs impacting the proteome on a global level, as well as specific hypotheses about functional elements in individual sequences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Discovering molecular features of intrinsically disordered regions by using evolution for contrastive learning</title>
      <link>http://www.alexluresearch.com/publication/reverse-homology/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/reverse-homology/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CytoImageNet: A large-scale pretraining dataset for bioimage transfer learning</title>
      <link>http://www.alexluresearch.com/publication/cytoimagenet/</link>
      <pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/cytoimagenet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Improved Conditional Flow Models for Molecule to Image Synthesis</title>
      <link>http://www.alexluresearch.com/publication/conditional_flow/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/conditional_flow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evolution Is All You Need: Phylogenetic Augmentation for Contrastive Learning</title>
      <link>http://www.alexluresearch.com/publication/evolution_is_all_you_need/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/evolution_is_all_you_need/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Models</title>
      <link>http://www.alexluresearch.com/project/out-of-sample/</link>
      <pubDate>Tue, 03 Mar 2020 17:18:58 -0500</pubDate>
      <guid>http://www.alexluresearch.com/project/out-of-sample/</guid>
      <description>&lt;img src=&#34;coos_preprint.png&#34;&gt;
&lt;p&gt;In addition to learning biological signal, a good machine learning model will be robust to non-biological, technical variation. Unfortunately, getting a model that learns just biological signal while ignoring technical variation can be difficult. Especially when you&amp;rsquo;re working with a purely data-driven model, both sources of variation can contribute to the predictiveness of the model. For example, large-scale image screens that parallelize many experiments at once might image experiments in the same order each time. The microscope gradually heats up as it operates, meaning the final set of experiments will be brighter than the first step of experiments, so the model might learn that image intensity can discriminate these experiments&lt;/p&gt;
&lt;p&gt;While biological signal (hopefully) produces general information, technical variation does not. If you scrambled the order of experiments in new screens, you might see a drop in performance, if the model has indeed learned to rely on technical variation as part of its decision-making. A growing concern in machine learning is that we may be overestimating how generalizable models are with standard techniques. Typically, an expert will evaluate their method by holding out some data, and then evaluating performance on that data to simulate the condition where the classifier is given fresh, unseen data. However, these types of methods don&amp;rsquo;t capture the cases where there may be changes in the way the data is produced and generated - for example, different hospitals have different instruments, so classifiers shown to work on one hospital&amp;rsquo;s data will not always work as well for another&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;To help machine learning experts develop methods that are robust to new data from different sources, &lt;a href=&#39;https://arxiv.org/abs/1906.07282&#39;&gt;we released a dataset where evaluation data increasingly differs from the data the experts are provided with to develop their models&lt;/a&gt;. For example, our hardest dataset comprises of data collected from a different laboratory in Ottawa, under a different microscope. We found that all of the current methods used to classify cells are not robust when the new data is different enough from the original data.&lt;/p&gt;
&lt;img src=&#34;BEN.png&#34;&gt;
&lt;p&gt;We found one surprisingly simple trick can make deep learning models robust to batch effects - &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.10.14.512286v1&#34;&gt;simply by re-arranging the order of training data so all datapoints in the batch to the neural network are sampled from the same experiment&lt;/a&gt;. This trick interacts with batch normalization layers present in most modern deep learning architectures. These layers are typically meant to stabilize training, by making sure that the output of each convolutional layer in a neural network is scaled to the mean and standard deviation of a batch. We realized that these layers could also be used to &amp;ldquo;subtract&amp;rdquo; batch effects during training and inference: by averaging samples from the same experiment together, the biological treatment effects &amp;ldquo;cancel out&amp;rdquo;, leaving just the batch effects alone to be standardized out from individual datapoints. Despite its simplicity, this method is outstandingly effective, outperforming much more advanced approaches, and generalizing across different strategies including supervised classification, self-supervised representation learning, and even transfer learning strategies where new datasets employing different fluorescent markers are totally unseen.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Cells Out of Sample (COOS) dataset and benchmarks for measuring out-of-sample generalization of image classifiers</title>
      <link>http://www.alexluresearch.com/publication/coos/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/coos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>YeastSpotter: accurate and parameter-free web segmentation for microscopy images of yeast cells</title>
      <link>http://www.alexluresearch.com/publication/yeastspotter/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/yeastspotter/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning unsupervised feature representations for single cell microscopy images with paired cell inpainting</title>
      <link>http://www.alexluresearch.com/publication/paired-cell-inpainting/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/paired-cell-inpainting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integrating images from multiple microscopy screens reveals diverse patterns of change in the subcellular localization of proteins</title>
      <link>http://www.alexluresearch.com/publication/integrating-yeast-images/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/integrating-yeast-images/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Influence of repetitive mechanical loading on MMP2 activity in tendon fibroblasts</title>
      <link>http://www.alexluresearch.com/publication/mmp2/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/mmp2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Unsupervised kNN Method to Systematically Detect Changes in Protein Localization in High-Throughput Microscopy Images</title>
      <link>http://www.alexluresearch.com/publication/knn/</link>
      <pubDate>Thu, 21 Jul 2016 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/knn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Angiopoietin‚Äêlike 4 promotes angiogenesis in the tendon and is increased in cyclically loaded tendon fibroblasts</title>
      <link>http://www.alexluresearch.com/publication/angiopoietin/</link>
      <pubDate>Wed, 16 Dec 2015 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/angiopoietin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accumulation of oxidized LDL in the tendon tissues of C57BL/6 or apolipoprotein E knock-out mice that consume a high fat diet: potential impact on tendon health</title>
      <link>http://www.alexluresearch.com/publication/oxidized-ldl/</link>
      <pubDate>Fri, 12 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/oxidized-ldl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhanced collagen type I synthesis by human tenocytes subjected to periodic in vitro mechanical stimulation</title>
      <link>http://www.alexluresearch.com/publication/enhanced_collagen/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/enhanced_collagen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Podocalyxin Regulates Murine Lung Vascular Permeability by Altering Endothelial Cell Adhesion</title>
      <link>http://www.alexluresearch.com/publication/podocalyxin/</link>
      <pubDate>Fri, 10 Oct 2014 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/podocalyxin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mast cells exert pro-inflammatory effects of relevance to the pathophyisology of tendinopathy</title>
      <link>http://www.alexluresearch.com/publication/mast_cells/</link>
      <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
      <guid>http://www.alexluresearch.com/publication/mast_cells/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
